# -*- coding: utf-8 -*-
"""rekomendasifixxxx.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15g8mCkFoMuQWULfFBS925556X-C9IzBz

## **Import Library**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping

"""## **Load Data**

Data makanan dibaca dari file food.csv dan disimpan dalam DataFrame food_df.
Data penilaian pengguna dibaca dari file ratings.csv dan disimpan dalam rating_df.
"""

food_df = pd.read_csv("food.csv")
food_df.head()

rating_df = pd.read_csv("ratings.csv")
rating_df.head()

"""## **Data Understanding**

Mengecek Informasi data
"""

food_df.info()

"""Dataset berisi 400 entri makanan dengan 5 kolom, yaitu ID, nama, kategori, jenis (veg/non-veg), dan deskripsi. Semua kolom lengkap tanpa nilai kosong."""

rating_df.info()

"""Data rating pengguna terdiri dari 512 entri dengan 3 kolom: User_ID, Food_ID, dan Rating.
Terdapat 1 baris yang memiliki nilai kosong pada ketiga kolom tersebut.

**Exploratory Data Analysis**

Mengecek missing value pada data food
"""

food_df.isna().sum()

"""Tidak terdapat missing value pada data food

Mengecek missing value pada data rating
"""

rating_df.isna().sum()

"""Terdapat 1 baris missing value pada ketiga kolom tersebut.

Mengecek Duplikat
"""

food_df.duplicated()

rating_df.duplicated()

"""Tidak terdapat data duplikat dikedua dataset

Melihat informasi statistik data rating
"""

rating_df.describe()

"""User_ID berkisar 1–100 dengan rata-rata 49, dan Food_ID antara 1–309 dengan rata-rata 125. Rating memiliki rata-rata 5.4, median 5, dengan rentang nilai 1–10, menunjukkan distribusi penilaian yang merata."""

print('Jumlah makanan unik:', food_df['Name'].nunique())
print('tipe makanan: ', food_df['C_Type'].unique())
print('tipe vegetarian: ', food_df['Veg_Non'].unique())

"""Ditemukan duplikasi kategori "Korean" karena perbedaan spasi ('Korean' dan ' Korean'), dan hal ini akan dibersihkan agar konsisten."""

print('Jumlah Rating:', rating_df['Rating'].nunique())
print('Tipe Rating: ', rating_df['Rating'].unique())

"""Terdapat 10 jenis rating unik dari 1 hingga 10, dan satu nilai NaN pada kolom Rating yang akan dihapus untuk memastikan data bersih.

Distribusi tipe/kategori makanan
"""

plt.figure(figsize=(10, 6))
ax = sns.countplot(data=food_df, x='C_Type', palette='viridis')
for p in ax.patches:
    ax.text(p.get_x() + p.get_width()/2, p.get_height()+0.5, int(p.get_height()), ha='center')
plt.title('Jumlah Makanan berdasarkan Tipe')
plt.xlabel('Tipe Makanan')
plt.ylabel('Jumlah')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Grafik menunjukkan kategori makanan terbanyak adalah Indian (88), diikuti Healthy Food (58) dan Dessert (53).
Beberapa kategori seperti Korean dan Spanish hanya memiliki 1 makanan, dengan duplikasi label Korean yang perlu dibersihkan.

Distribusi tipe vegetarian
"""

plt.figure(figsize=(10, 6))
ax = sns.countplot(data=food_df, x='Veg_Non', palette='viridis')
for p in ax.patches:
    ax.text(p.get_x() + p.get_width()/2, p.get_height()+0.5, int(p.get_height()), ha='center')
plt.title('Jumlah Makanan berdasarkan Tipe Vegetarian')
plt.xlabel('Tipe Makanan')
plt.ylabel('Jumlah')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Grafik menunjukkan jumlah makanan berdasarkan tipe vegetarian, dengan 238 makanan veg dan 162 non-veg. Ini menunjukkan bahwa makanan vegetarian lebih dominan.

Distribusi rating
"""

plt.figure(figsize=(8, 6))
ax = sns.countplot(data=rating_df, x='Rating', palette='viridis')
for p in ax.patches:
    ax.text(p.get_x() + p.get_width()/2, p.get_height()+0.5, int(p.get_height()), ha='center')
plt.title('Distribusi Rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.tight_layout()
plt.show()

"""Grafik menunjukkan rating 3, 5, dan 10 paling sering muncul, sementara rating 8 paling sedikit. Distribusi rating bervariasi dan tidak simetris.

"""

plt.figure(figsize=(8, 6))
sns.boxplot(x=rating_df['Rating'], palette='viridis')
plt.title('Boxplot Rating')
plt.xlabel('Rating')
plt.show()

"""Berdasarkan grafik boxplot, tidak terdapat outlier, yang menunjukkan bahwa seluruh nilai rating berada dalam rentang yang wajar.

# **Content Based Filtering**

## **Data Preparation**

menggabungkan kategori yang sama tapi terpisah karna spasi
"""

food_df['C_Type'] = food_df['C_Type'].str.strip()
print('Tipe makanan setelah dibersihkan:', food_df['C_Type'].unique())

"""Kategori makanan yang sama namun terpisah karena spasi, seperti 'Korean' dan ' Korean', telah digabungkan.
Setelah dibersihkan, tipe makanan menjadi konsisten, terdiri dari 15 kategori unik.

menghapus kolom 'Describe' karena tidak dibutuhkan
"""

data = food_df.drop(columns=['Describe'])

"""Kolom 'C_Type' dan 'Veg_Non' digabung menjadi satu kolom baru 'combined', yang berisi informasi gabungan jenis makanan dan apakah makanan tersebut vegetarian atau non-vegetarian. Ini akan digunakan sebagai dasar untuk menghitung kesamaan antar item."""

data['combined'] = data['C_Type'] + ' ' + data['Veg_Non']

data.head()

"""TF-IDF Vectorization : mengubah teks di kolom 'combined' menjadi matriks TF-IDF menggunakan TfidfVectorizer. Matriks tersebut merepresentasikan seberapa penting tiap kata dalam setiap dokumen untuk analisis atau model machine learning."""

vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(data['combined'])

"""Ekstraksi Fitur dan Cosine Similarity : mengekstrak daftar kata dari TF-IDF dan menghitung kemiripan antar dokumen menggunakan cosine similarity. Hasilnya berupa matriks yang menunjukkan seberapa mirip setiap dokumen satu sama lain berdasarkan isi teksnya."""

feature_names = vectorizer.get_feature_names_out()
print("Ukuran matriks TF-IDF:", tfidf_matrix.shape)

cosine_sim = cosine_similarity(tfidf_matrix)
print("Ukuran matriks similaritas kosinus:", cosine_sim.shape)

# Konversi ke DataFrame
cm_df = pd.DataFrame(cosine_sim, index=data['Name'], columns=data['Name'])

cm_df

"""## **Model Development** dan **Recomendation**

Membuat fungsi rekomendasi berdasarkan kemiripan teks menggunakan matriks cosine similarity. Fungsi get_recommendation_df menerima nama item dan jumlah rekomendasi (top_k), lalu:

1. Mengambil data awal item yang dicari (df_awal).

2. Mengambil skor kemiripan tertinggi dari matriks kemiripan, kecuali item itu sendiri.

3. Mengambil data dari item yang paling mirip beserta skor kemiripannya.

4. Mengembalikan data awal dan daftar rekomendasi.
"""

def get_recommendation_df(item_name, top_k=5):
    df_awal = data[data['Name'] == item_name][['Name', 'C_Type', 'Veg_Non']].copy().reset_index(drop=True)

    sim_scores = cm_df[item_name].drop(index=item_name)
    top_similar = sim_scores.sort_values(ascending=False).head(top_k)

    df_rekomendasi = data.set_index('Name').loc[top_similar.index][['C_Type', 'Veg_Non']].copy()
    df_rekomendasi['Similarity'] = top_similar.values
    df_rekomendasi = df_rekomendasi.reset_index()

    return df_awal, df_rekomendasi

"""Contoh pemanggilan fungsi dengan item "Rosemary Roasted Vegetables" akan menampilkan data awal dan 5 rekomendasi teratas yang paling mirip."""

df_awal, df_rekomendasi = get_recommendation_df("Rosemary Roasted Vegetables", top_k=5)

# Tampilkan hasil
print("Data Awal:")
display(df_awal)

print("\nRekomendasi:")
display(df_rekomendasi)

"""## **Evaluasi**

Menggunakan Presicion
mengukur proporsi rekomendasi yang tepat dari keseluruhan item yang disarankan kepada pengguna. Precision pada top-N menunjukkan berapa banyak dari N rekomendasi teratas yang benar-benar relevan atau sesuai dengan preferensi pengguna.

$$
\text{Precision} = \frac{\text{Jumlah item rekomendasi yang relevan}}{\text{Total jumlah item yang direkomendasikan}}
$$

Semua 5 rekomendasi memenuhi kriteria tersebut → artinya semuanya relevan.

$$
\text{Precision@5} = \frac{5 \text{ item relevan}}{5 \text{ item yang direkomendasikan}} = 1.0 \text{ atau } 100\%
$$

# **Collaborative Filtering**

## **Data Preparation**

Menghapus missing value pada data rating
"""

rating_df = rating_df.dropna()

rating_df.isna().sum()

rating_df.head()

"""mengubah kolom User_ID dan Food_ID bertipe int, agar bisa diproses lebih lanjut secara numerik, terutama untuk encoding dan pemodelan."""

rating_df['User_ID'] = rating_df['User_ID'].astype(int)
rating_df['Food_ID'] = rating_df['Food_ID'].astype(int)

"""Encoding ID User dan Food : mengubah ID pengguna dan makanan dari bentuk asli ke angka berurutan agar cocok untuk model machine learning. Kamus dibuat untuk konversi dua arah antara ID asli dan angka, lalu data rating_df di-update dengan ID yang sudah diencoding. Proses ini memudahkan pemrosesan dan pelatihan model."""

user_ids = rating_df['User_ID'].unique().tolist()
food_ids = rating_df['Food_ID'].unique().tolist()

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

food_to_food_encoded = {x: i for i, x in enumerate(food_ids)}
food_encoded_to_food = {i: x for i, x in enumerate(food_ids)}

# Terapkan encoding ke DataFrame
rating_df['User_ID'] = rating_df['User_ID'].map(user_to_user_encoded)
rating_df['Food_ID'] = rating_df['Food_ID'].map(food_to_food_encoded)

"""Normalisasi rating ke 0-1 membuat data lebih konsisten, membantu model machine learning lebih stabil dalam proses training."""

rating_df['Rating'] = rating_df['Rating'] / 10.0

print("List User_ID:", user_ids)
print("Encoded User_ID:", user_to_user_encoded)
print("Decoded User_ID dari angka:", user_encoded_to_user)

print("List Food_ID:", food_ids)
print("Encoded Food_ID:", food_to_food_encoded)
print("Decoded Food_ID dari angka:", food_encoded_to_food)

rating_df.head()

"""Pengacakan Data (Shuffle)"""

rating_df = rating_df.sample(frac=1, random_state=42).reset_index(drop=True)

rating_df.head()

"""Split data dengan rasio 80:20 membagi data menjadi 80% untuk pelatihan dan 20% untuk pengujian, lalu menyiapkan input dan output agar model dapat dilatih dan diuji."""

train_df, val_df = train_test_split(rating_df, test_size=0.2, random_state=42)

print(f'Jumlah data training: {len(train_df)}')
print(f'Jumlah data validation: {len(val_df)}')

x_train = np.array(list(zip(train_df['User_ID'], train_df['Food_ID'])))
y_train = train_df['Rating']

x_val = np.array(list(zip(val_df['User_ID'], val_df['Food_ID'])))
y_val = val_df['Rating']

"""## **Model Development** dan **Recomendation**

model rekomendasi berbasis embedding menggunakan TensorFlow. Model membuat representasi vektor (embedding) untuk pengguna dan makanan, lalu menghitung interaksi mereka dengan dot product ditambah bias. Hasilnya diproses lewat fungsi sigmoid untuk memprediksi rating dalam rentang 0-1.
"""

class RecommenderNet(tf.keras.Model):
    def __init__(self, num_users, num_food, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.user_embedding = layers.Embedding(
            num_users, embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)

        self.food_embedding = layers.Embedding(
            num_food, embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.food_bias = layers.Embedding(num_food, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        food_vector = self.food_embedding(inputs[:, 1])
        food_bias = self.food_bias(inputs[:, 1])

        # Gunakan reduce_sum untuk dot product
        dot_user_food = tf.reduce_sum(user_vector * food_vector, axis=1, keepdims=True)

        # Tambahkan bias
        x = dot_user_food + user_bias + food_bias

        # Output sigmoid, dan squeeze agar bentuknya (batch,)
        return tf.nn.sigmoid(tf.squeeze(x, axis=1))

num_users = len(user_to_user_encoded)
print("Jumlah user:", num_users)

num_food = len(food_to_food_encoded)
print("Jumlah makanan (food):", num_food)

"""membuat dan mengompilasi model dengan embedding 50, menggunakan loss Binary Crossentropy, optimizer Adam, dan metrik Mean Absolute Error."""

model = RecommenderNet(num_users, num_food, 50)

model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.MeanAbsoluteError()]
)

_ = model(tf.constant([[0, 0]]))

model.summary()

"""Callback EarlyStopping menghentikan pelatihan saat model tidak membaik untuk mencegah overfitting."""

early_stopping = EarlyStopping(
    monitor='val_mean_absolute_error',
    patience=5,
    restore_best_weights=True
)

"""Training Model"""

history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=8,
    epochs=100,
    validation_data=(x_val, y_val),
    callbacks=[early_stopping]
)

plt.figure(figsize=(12, 8))
plt.plot(history.history['mean_absolute_error'], label='Training MAE')
plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')
plt.title('Training and Validation Mean Absolute Error (MAE)')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.grid(True)
plt.show()

"""**recommend_for_user** yang merekomendasikan makanan baru kepada user berdasarkan prediksi model terhadap makanan yang belum pernah dirating user tersebut, dan **show_user_rated_food** yang menampilkan daftar makanan beserta rating yang sudah diberikan user. Fungsi rekomendasi memilih makanan dengan skor prediksi tertinggi, sedangkan fungsi rating menampilkan data asli hasil rating user. Contoh penggunaan menunjukkan kedua hasil ini untuk user dengan ID 2, membantu memahami preferensi dan rekomendasi yang diberikan."""

def recommend_for_user(user, top_k=5):
    if user not in user_to_user_encoded:
        return "User ID tidak ditemukan."
    u_enc = user_to_user_encoded[user]
    rated = rating_df[rating_df['User_ID'] == u_enc]['Food_ID'].tolist()
    not_rated = [food_encoded_to_food[i] for i in food_encoded_to_food if i not in rated]

    preds = model.predict(np.array([[u_enc, food_to_food_encoded[f]] for f in not_rated])).flatten()
    top_idx = np.argsort(preds)[::-1][:top_k]

    res = food_df[food_df['Food_ID'].isin([food_encoded_to_food[food_to_food_encoded[not_rated[i]]] for i in top_idx])].copy()
    res['Predicted_Rating'] = preds[top_idx] * 10
    return res[['Name', 'C_Type', 'Veg_Non', 'Predicted_Rating']]


def show_user_rated_food(user):
    if user not in user_to_user_encoded:
        return "User ID tidak ditemukan."
    u_enc = user_to_user_encoded[user]
    rated = rating_df[rating_df['User_ID'] == u_enc].copy()
    rated['Food_ID_Orig'] = rated['Food_ID'].map(food_encoded_to_food)
    merged = rated.merge(food_df, left_on='Food_ID_Orig', right_on='Food_ID')
    merged['Rating'] *= 10
    return merged[['Name', 'C_Type', 'Veg_Non', 'Rating']]


# Contoh penggunaan
user = 2
print("Makanan sudah dirating:")
display(show_user_rated_food(user))
print("Rekomendasi makanan:")
display(recommend_for_user(user))

"""## **Evaluasi**

**Mean Absolute Error (MAE)** digunakan untuk mengukur seberapa besar rata-rata kesalahan antara nilai rating aktual dengan rating yang diprediksi oleh model. Semakin kecil nilai MAE, semakin baik kinerja model.

$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} | y_i - \hat{y}_i |
$$


Selama 16 epoch pelatihan, MAE pada data training menurun drastis dari 0.2509 menjadi 0.0699, menunjukkan model belajar dengan baik. Namun, pada data validasi, penurunan MAE hanya terjadi di awal (dari 0.2434 ke 0.2395 hingga epoch 11), lalu stagnan hingga 0.2404 di epoch 16, menandakan overfitting, di mana model kurang mampu memprediksi data baru secara akurat.
"""